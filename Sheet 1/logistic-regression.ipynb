{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'target_names', 'images', 'DESCR'])\n",
      "(1797, 64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "print(digits.keys())\n",
    "data = digits[\"data\"]\n",
    "images = digits[\"images\"]\n",
    "target = digits[\"target\"]\n",
    "target_names = digits[\"target_names\"]\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract instances showing \"3\" or \"8\", append a column of \"1s\" and create a vector of ground-truth labels where 1 corresponds to 3 and -1 to 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data[np.logical_or(target == 3, target == 8)]\n",
    "y = target[np.logical_or(target == 3, target == 8)]\n",
    "\n",
    "X = np.concatenate((X, np.ones([len(y),1])), axis = 1)\n",
    "\n",
    "y[y==3] = 1\n",
    "y[y==8] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Classification with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_splits = 10\n",
    "lambdas = [0.001,0.01,0.1,1,10,100,1000]\n",
    "scores = np.zeros([len(lambdas), 2]) # save mean score and std for each lambda\n",
    "\n",
    "for i, C in enumerate(lambdas):\n",
    "    logistic = LogisticRegression(C = C)\n",
    "    curr_scores = cross_val_score(logistic, X, y, cv = num_splits)\n",
    "    scores[i,0] = np.average(curr_scores)\n",
    "    scores[i,1] = np.std(curr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:,.4f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>C</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.9688</td>\n",
       "      <td>0.0531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0100</th>\n",
       "      <td>0.9691</td>\n",
       "      <td>0.0464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1000</th>\n",
       "      <td>0.9860</td>\n",
       "      <td>0.0288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0000</th>\n",
       "      <td>0.9860</td>\n",
       "      <td>0.0288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0000</th>\n",
       "      <td>0.9803</td>\n",
       "      <td>0.0283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.0000</th>\n",
       "      <td>0.9775</td>\n",
       "      <td>0.0304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1,000.0000</th>\n",
       "      <td>0.9747</td>\n",
       "      <td>0.0341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "C            mean    std\n",
       "0.0010     0.9688 0.0531\n",
       "0.0100     0.9691 0.0464\n",
       "0.1000     0.9860 0.0288\n",
       "1.0000     0.9860 0.0288\n",
       "10.0000    0.9803 0.0283\n",
       "100.0000   0.9775 0.0304\n",
       "1,000.0000 0.9747 0.0341"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.DataFrame(\n",
    "        data = scores,\n",
    "        index = lambdas,\n",
    "        columns = ['mean','std'])\n",
    "        .rename_axis('C', axis = 'columns'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the prediction varies only very slowly when modifying the regularization parameter. The best accuracy is obtained for $\\lambda=0.1, 1, 10$, thus a very large range. In the following we will proceed using $\\lambda=1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Optimization Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(beta, X):\n",
    "    # if X*beta > 0 --> y=1, if X*beta < 0 --> y=-1\n",
    "    y = (X.dot(beta) >= 0) * 2 - 1\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def zero_one_loss(y_prediction, y_truth):\n",
    "    return np.sum(np.not_equal(y_prediction, y_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient(beta, X, y, lambda_ = 1):\n",
    "    # distinguish the cases of one single / several training instances\n",
    "    if np.isscalar(y):\n",
    "        grad = beta / lambda_ - sigmoid(-X.dot(beta) * y) * y * X\n",
    "    else:\n",
    "        grad = beta / lambda_ - np.average((sigmoid(-X.dot(beta) * y) * y)[:,None] * X, axis = 0)\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GD(X, y, beta, tau, m):\n",
    "    for _ in range(m):\n",
    "        beta = beta - tau * gradient(beta, X, y)\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "def SGD_with_replacement(X, y, beta, tau_0, gamma, m):\n",
    "    N = y.shape[0]\n",
    "    for i in range(m):\n",
    "        tau = tau_0 / (1 + gamma * i)\n",
    "        index = np.random.randint(low=0, high=N)\n",
    "        beta = beta - tau * gradient(beta, X[index,:], y[index])\n",
    "    return beta\n",
    "\n",
    "def SGD_without_replacement(X, y, beta, tau_0, gamma, m):\n",
    "    X, y = shuffle(X,y)\n",
    "    for i in range(m):\n",
    "        tau = tau_0 / (1 + gamma * i)\n",
    "        beta = beta - tau * gradient(beta, X[i,:], y[i])\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SG_minibatch(X, y, beta, B, tau_0, gamma, m):\n",
    "    # here we do not replace the samples since there would not be enough samples\n",
    "    # to perform m=150 optimization steps for larger B\n",
    "    for i in range(m):\n",
    "        X, y = shuffle(X,y)\n",
    "        tau = tau_0 / (1 + gamma * i)\n",
    "        beta = beta - tau * gradient(beta, X[:B,:], y[:B])\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SG_momentum(X, y, beta, tau_0, gamma, mu, m):\n",
    "    X, y = shuffle(X,y)\n",
    "    # initialize g\n",
    "    g = np.zeros(len(beta))\n",
    "    for i in range(m):\n",
    "        tau = tau_0 / (1 + gamma * i)\n",
    "        g = mu * g + (1 - mu) * gradient(beta, X[i,:], y[i])\n",
    "        beta = beta - tau * g\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ADAM(X, y, beta, m, tau=10**-4, mu1=0.9, mu2=0.999, eps=10**-8):\n",
    "    X, y = shuffle(X,y)\n",
    "    # initialize g, q\n",
    "    g = np.zeros(len(beta))\n",
    "    q = np.zeros(len(beta))\n",
    "    for i in range(m):\n",
    "        grad = gradient(beta, X[i,:], y[i])\n",
    "        g = mu1 * g + (1 - mu1) * grad\n",
    "        q = mu2 * q + (1 - mu2) * np.square(grad)\n",
    "        beta = beta - tau / (np.sqrt(q) + eps) * g\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SAGD(X, y, beta, m, tau_0, gamma):\n",
    "    g_stored = -y[:,None] * X * sigmoid(-y * X.dot(beta))[:,None]\n",
    "    g = np.average(g_stored, axis=0)\n",
    "    X, y = shuffle(X, y)\n",
    "    for i in range(m):\n",
    "        tau = tau_0 / (1 + gamma * i)\n",
    "        g[i] = -y[i] * np.dot(X[i,:].T, sigmoid(-y[i] * np.dot(X[i,:], beta)))\n",
    "        g = g + 1 / N * (g[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Newton_Raphson(X, y, beta, m, lambda_=0.001):# hier muss lambda kleiner gewählt werden, für lambda=1 divergiert das ganze\n",
    "    N,D = X.shape\n",
    "    for _ in range(m):\n",
    "        z = X.dot(beta)\n",
    "        y_tilde = y / sigmoid(-y * z)\n",
    "        W = np.diag(lambda_ / N * sigmoid(z) * sigmoid(-z))\n",
    "        inv = np.linalg.inv(1 / lambda_ * np.identity(D) + np.dot(X.T, np.dot(W, X)))\n",
    "        beta = beta + np.dot(inv, np.dot(X.T, np.dot(W, y_tilde)) - beta / lambda_)\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dual_coordinate_ascent(X, y, m, lambda_=0.0001):\n",
    "    # initialization:\n",
    "    N = X.shape[0]\n",
    "    alpha = np.random.uniform(size=N)\n",
    "    beta = lambda_ * np.average((alpha * y)[:,None] * X, axis=0)\n",
    "    X, y = shuffle(X, y)\n",
    "    for i in range(m):\n",
    "        f_prime = y[i] * np.dot(X[i,:], beta) + np.log(alpha[i] / (1 - alpha[i]))\n",
    "        f_2prime = lambda_ / N * np.dot(X[i,:], X[i,:].T) + 1 / (alpha[i] * (1 - alpha[i]))\n",
    "        alpha_old = alpha[i].copy()\n",
    "        alpha[i] = max(0, min(1, alpha[i] - f_prime / f_2prime))\n",
    "        beta += lambda_ / N * y[i] * X[i,:] * (alpha[i] - alpha_old)\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0185185185185\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split (X, y, test_size = 0.3 ,random_state = 0)\n",
    "beta = dual_coordinate_ascent(X_train, y_train, 150)\n",
    "\n",
    "errors = zero_one_loss(predict(beta, X_test), y_test)\n",
    "print(errors / len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0185185185185\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split (X, y, test_size = 0.3 ,random_state = 0)\n",
    "beta = np.zeros(65)\n",
    "beta = GD(X_train, y_train, beta, 0.001, 10)\n",
    "\n",
    "errors = zero_one_loss(predict(beta, X_test), y_test)\n",
    "print(errors / len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0185185185185\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split (X, y, test_size = 0.3 ,random_state = 0)\n",
    "beta = np.zeros(65)\n",
    "beta = Newton_Raphson(X_train, y_train, beta, 20)\n",
    "\n",
    "errors = zero_one_loss(predict(beta, X_test), y_test)\n",
    "print(errors / len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00925925925926\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split (X, y, test_size = 0.3 ,random_state = 0)\n",
    "beta = np.zeros(65)\n",
    "tau_0 = 0.001\n",
    "gamma = 0.0001\n",
    "beta = SGD_without_replacement(X_train, y_train, beta, tau_0, gamma, 150)\n",
    "\n",
    "errors = zero_one_loss(predict(beta, X_test), y_test)\n",
    "print(errors / len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0185185185185\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split (X, y, test_size = 0.3 ,random_state = 0)\n",
    "beta = np.zeros(65)\n",
    "tau_0 = 0.001\n",
    "gamma = 0.0001\n",
    "beta = SG_minibatch(X_train, y_train, beta, 1, tau_0, gamma, 150)\n",
    "\n",
    "errors = zero_one_loss(predict(beta, X_test), y_test)\n",
    "print(errors / len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00925925925926\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split (X, y, test_size = 0.3 ,random_state = 0)\n",
    "beta = np.zeros(65)\n",
    "tau_0 = 0.001\n",
    "gamma = 0.0001\n",
    "mu = 0.1\n",
    "beta = ADAM(X_train, y_train, beta, 150)\n",
    "\n",
    "errors = zero_one_loss(predict(beta, X_test), y_test)\n",
    "print(errors / len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'float' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-eb065447abc3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSAGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m150\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzero_one_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merrors\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-ead2ff670cf2>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(beta, X)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m# if X*beta > 0 --> y=1, if X*beta < 0 --> y=-1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'float' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split (X, y, test_size = 0.3 ,random_state = 0)\n",
    "beta = np.zeros(65)\n",
    "tau_0 = 0.001\n",
    "gamma = 0.0001\n",
    "mu = 0.1\n",
    "beta = SAGD(X_train, y_train, beta, 150)\n",
    "\n",
    "errors = zero_one_loss(predict(beta, X_test), y_test)\n",
    "print(errors / len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001 0.1 0.0001 3\n",
      "0.001 0.1 0.001 4\n",
      "0.001 0.1 0.01 1\n",
      "0.001 0.2 0.0001 4\n",
      "0.001 0.2 0.001 1\n",
      "0.001 0.2 0.01 3\n",
      "0.001 0.5 0.0001 7\n",
      "0.001 0.5 0.001 1\n",
      "0.001 0.5 0.01 1\n",
      "0.01 0.1 0.0001 36\n",
      "0.01 0.1 0.001 35\n",
      "0.01 0.1 0.01 25\n",
      "0.01 0.2 0.0001 57\n",
      "0.01 0.2 0.001 26\n",
      "0.01 0.2 0.01 13\n",
      "0.01 0.5 0.0001 29\n",
      "0.01 0.5 0.001 24\n",
      "0.01 0.5 0.01 9\n",
      "0.1 0.1 0.0001 85\n",
      "0.1 0.1 0.001 92\n",
      "0.1 0.1 0.01 59\n",
      "0.1 0.2 0.0001 134\n",
      "0.1 0.2 0.001 105\n",
      "0.1 0.2 0.01 75\n",
      "0.1 0.5 0.0001 81\n",
      "0.1 0.5 0.001 75\n",
      "0.1 0.5 0.01 55\n"
     ]
    }
   ],
   "source": [
    "X_tr, X_test, y_tr, y_test = train_test_split (X, y, test_size = 0.3 ,random_state = 0)\n",
    "\n",
    "for (tau_0, mu, gamma) in itertools.product([0.001, 0.01, 0.1], [0.1, 0.2, 0.5], [0.0001, 0.001, 0.01]):\n",
    "    kf = KFold(y_tr.shape[0], n_folds=10)\n",
    "    errors = 0\n",
    "    for train, val in kf:\n",
    "        beta = SGD_without_replacement(X_tr[train], y_tr[train], beta, tau_0, gamma, 150)\n",
    "        errors += zero_one_loss(predict(beta, X_tr[val]), y_tr[val])\n",
    "    print(tau_0, mu, gamma, errors)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
