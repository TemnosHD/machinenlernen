{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_diag(Y, stateX):\n",
    "    diag = np.identity(len(Y))\n",
    "    return diag * Y[:, stateX]\n",
    "\n",
    "def normalize(vector):\n",
    "    return vector / np.sum(vector, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HMM():\n",
    "    def __init__(self, T, B, obs, pi):\n",
    "        \"\"\"\n",
    "        discrete state HMM. \n",
    "        assume that the states are given as integers, i.e. state1 = 0, state2 = 1 etc.\n",
    "        --> use states as indices\n",
    "        \n",
    "        A specifying the transition matrix T of the hidden markov chain (x-variables), \n",
    "        B specifying the transition matrix B from hidden state to observations (emission matrix)\n",
    "        obs specifying a sequence of observations\n",
    "        \n",
    "        \"\"\"\n",
    "        self.T = T # transition matrix\n",
    "        self.B = B #  emission matrix\n",
    "        self.o = obs # sequence of integers\n",
    "        self.pi = pi # probability vector, containing the probs of the initial (hidden) state\n",
    "        \n",
    "    def alpha(self, t):\n",
    "        \"\"\"\n",
    "        forward-pass\n",
    "        \"\"\"\n",
    "        ############\n",
    "        # wikipedia style: see \n",
    "        # https://en.wikipedia.org/wiki/Forward%E2%80%93backward_algorithm#RussellNorvig10\n",
    "        if t > 0:\n",
    "            return normalize(construct_diag(self.B, self.o[t]) @ self.T.T @ self.alpha(t - 1))\n",
    "        else:\n",
    "            return normalize(construct_diag(self.B, self.o[0]) @ self.T.T @ self.pi)\n",
    "            \n",
    "\n",
    "    def beta(self, t):\n",
    "        \"\"\"\n",
    "        backward-pass\n",
    "        \"\"\"\n",
    "        T = len(self.o) - 1\n",
    "        if t < T:\n",
    "            return normalize(self.T @ construct_diag(self.B, self.o[t]) @ self.beta(t+1))\n",
    "        else:\n",
    "            return np.ones(len(self.B[:, 0]))\n",
    "\n",
    "    def forward_backward(self):\n",
    "        probs = np.zeros((len(self.o), len(self.T)))\n",
    "        for j in range(len(probs)):\n",
    "            probs[j] = self.alpha(j) * self.beta(j) / np.sum(self.alpha(j) * self.beta(j))\n",
    "        return probs, np.argmax(probs, axis = 1)\n",
    "\n",
    "    def viterbi(self):\n",
    "        T = len(self.o)\n",
    "        K = self.T.shape[0]\n",
    "        T1 = np.zeros((K, T))\n",
    "        T2 = np.zeros((K, T)) # holds the backpointers\n",
    "        T1[:, 0] = self.pi*self.B[:,self.o[0]] #initialization\n",
    "        for t in range(1, T):\n",
    "            s_temp = np.zeros((K, K))\n",
    "            for j in range(K):\n",
    "                s_temp[j]  = T1[:, t-1] * self.T[:,j] * self.B[j, self.o[t]]\n",
    "                # compute the temporary rows from which the maximum is chosen, i.e. from which previous state\n",
    "                # the according probability was computed\n",
    "            T1[:, t] = np.max(s_temp, axis = 1) \n",
    "            # pick the max. prob out of all possible prev. states (for all states simultanously) \n",
    "            T2[:, t] = np.argmax(s_temp, axis = 1) \n",
    "            #from which state the according max. prob. was computed (for all states simult.)\n",
    "        \n",
    "        # do the backtracing\n",
    "        states = np.zeros(T, dtype = np.int32)\n",
    "        states[-1] = np.argmax(T1[:, -1])\n",
    "        for t in range(T-2, -1, -1): # exclude T-1 (last index)\n",
    "            states[t] = T2[states[t+1], t+1]\n",
    "        return states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application: Chimpanzee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fwd/Bwd encoded state sequence:  [0 0 0 0 1 0 1 1 1 0 1 1 1 1 1 0 0 0 0 1]\n",
      "Viterbi encoded state sequence:  [0 0 0 0 1 0 1 1 1 0 1 1 1 1 1 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "A = np.ones((2, 2)) * 0.5\n",
    "B = np.array([[0.5, 0.4, 0.1], [0.4, 0.1, 0.5]])\n",
    "o = [0,1,1,0,2,0,2,2,2,0,2,2,2,2,2,0,0,1,1,2]\n",
    "\n",
    "hmm = HMM(A, B, o, np.array([0.5, 0.5]))\n",
    "probs, states = hmm.forward_backward()\n",
    "print('Fwd/Bwd encoded state sequence: ', states)\n",
    "print('Viterbi encoded state sequence: ', hmm.viterbi())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward-backward and Viterbi algorithm yield the same sequence of hidden states (due to symmetry of transition matrix?). They do not if the transition matrix is not symmetric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fwd/Bwd encoded state sequence:  [1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0]\n",
      "Viterbi encoded state sequence:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# again the chimpanzee with another transition matrix\n",
    "A = np.array([[0.99, 0.01], [0.3, 0.7]])\n",
    "B = np.array([[0.5, 0.4, 0.1], [0.4, 0.1, 0.5]])\n",
    "o = [2,1,1,0,2,0,2,2,2,0,2,2,2,2,2,0,0,1,1,2]\n",
    "\n",
    "hmm = HMM(A, B, o, np.array([0.5, 0.5]))\n",
    "probs, states = hmm.forward_backward()\n",
    "print('Fwd/Bwd encoded state sequence: ', states)\n",
    "print('Viterbi encoded state sequence: ', hmm.viterbi())\n",
    "#print('via backpointer so very nice  : ', hmm.viterbi_bp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
